{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd747432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559b19f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper =api_wrapper_arxiv,description=\"Query Arxiv Papers\")\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08de53a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2025-07-02\\nTitle: AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing\\nAuthors: Yinwang Ren, Yangyang Liu, Tang Ji, Xun Xu\\nSummary: AI agents are autonomous systems designed to perceive, reason, and act within\\ndynamic environments. With the rapid advancements in generative AI (GenAI),\\nlarge language models (LLMs) and multimodal large language models (MLLMs) have\\nsignificantly improved AI agents' capabilities in semantic comprehension,\\ncomplex reasoning, \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "arxiv.invoke(\"Agentic AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0da5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper =api_wrapper_wiki,description=\"Query Arxiv Papers\")\n",
    "print(wiki.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e4bcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Computer vision\\nSummary: Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the form of decisions. \"Understanding\" in this context signifies the transformation of visual images (the input to the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This i'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "wiki.invoke(\"What is Computer Vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72896386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295ec43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meera\\AppData\\Local\\Temp\\ipykernel_28016\\637379855.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "### Tavily Search Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a5275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Ultralytics YOLO Docs: Home',\n",
       "  'url': 'https://docs.ultralytics.com/',\n",
       "  'content': \"Introducing Ultralytics YOLO11, the latest version of the acclaimed real-time object detection and image segmentation model. YOLO11 is built on cutting-edge advancements in deep learning and computer vision, offering unparalleled performance in terms of speed and accuracy. Its streamlined design makes it suitable for various applications and easily adaptable to different hardware platforms, from edge devices to cloud APIs. [...] Ultralytics YOLO is the latest advancement in the acclaimed YOLO (You Only Look Once) series for real-time object detection and image segmentation. It builds on previous versions by introducing new features and improvements for enhanced performance, flexibility, and efficiency. YOLO supports various vision AI tasks such as detection, segmentation, pose estimation, tracking, and classification. Its state-of-the-art architecture ensures superior speed and accuracy, making it suitable for diverse [...] Discover Ultralytics' latest state-of-the-art YOLO11 models and their capabilities\\n\\nYOLO11 Models ðŸš€ NEW\\n\\n  Open Source, AGPL-3.0\\n\\nUltralytics offers two YOLO licenses: AGPL-3.0 and Enterprise. Explore YOLO on GitHub.\\n\\nYOLO License\\n\\nWatch: How to Train a YOLO11 model on Your Custom Dataset in Google Colab.\\n\\n## YOLO: A Brief History\",\n",
       "  'score': 0.8215175},\n",
       " {'title': 'Ultralytics YOLO - GitHub',\n",
       "  'url': 'https://github.com/ultralytics/ultralytics',\n",
       "  'content': 'Ultralytics supports a wide range of YOLO models, from early versions like YOLOv3 to the latest YOLO11. The tables below showcase YOLO11 models pretrained on the COCO dataset for Detection, Segmentation, and Pose Estimation. Additionally, Classification models pretrained on the ImageNet dataset are available. Tracking mode is compatible with all Detection, Segmentation, and Pose models. All Models are automatically downloaded from the latest Ultralytics release upon first use. [...] | Model | size (pixels) | acc top1 | acc top5 | Speed CPU ONNX (ms) | Speed T4 TensorRT10 (ms) | params (M) | FLOPs (B) at 224 |\\n| --- | --- | --- | --- | --- | --- | --- | --- |\\n| YOLO11n-cls | 224 | 70.0 | 89.4 | 5.0 Â± 0.3 | 1.1 Â± 0.0 | 1.6 | 0.5 |\\n| YOLO11s-cls | 224 | 75.4 | 92.7 | 7.9 Â± 0.2 | 1.3 Â± 0.0 | 5.5 | 1.6 |\\n| YOLO11m-cls | 224 | 77.3 | 93.9 | 17.2 Â± 0.4 | 2.0 Â± 0.0 | 10.4 | 5.0 |\\n| YOLO11l-cls | 224 | 78.3 | 94.3 | 23.2 Â± 0.3 | 2.8 Â± 0.0 | 12.9 | 6.2 | [...] | Model | size (pixels) | mAPtest 50 | Speed CPU ONNX (ms) | Speed T4 TensorRT10 (ms) | params (M) | FLOPs (B) |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| YOLO11n-obb | 1024 | 78.4 | 117.6 Â± 0.8 | 4.4 Â± 0.0 | 2.7 | 17.2 |\\n| YOLO11s-obb | 1024 | 79.5 | 219.4 Â± 4.0 | 5.1 Â± 0.0 | 9.7 | 57.5 |\\n| YOLO11m-obb | 1024 | 80.9 | 562.8 Â± 2.9 | 10.1 Â± 0.4 | 20.9 | 183.5 |\\n| YOLO11l-obb | 1024 | 81.0 | 712.5 Â± 5.0 | 13.5 Â± 0.6 | 26.2 | 232.0 |',\n",
       "  'score': 0.798077},\n",
       " {'title': 'What is YOLO? The Ultimate Guide [2025] - Roboflow Blog',\n",
       "  'url': 'https://blog.roboflow.com/guide-to-yolo-models/',\n",
       "  'content': 'Second, YOLO models continue to lead the way in terms of accuracy. The YOLOv7 model, the latest in the family of models as of November 2022, has state-of-the-art performance when measured against the MS COCO object detection dataset. While there are other great models out there, YOLO has a strong reputation for its accuracy. [...] YOLOv3 was released in 2018. (The YOLOv3 paper is perhaps one of the most readable papers in computer vision research given its colloquial tone.)\\n\\nYOLOv3 built upon previous models by adding an objectness score to bounding box prediction, added connections to the backbone network layers, and made predictions at three separate levels of granularity to improve performance on smaller objects.\\n\\n## The newest YOLO models: A deep dive [...] YOLOv8 was developed by Ultralytics, who also created the influential and industry-defining YOLOv5 model. YOLOv8 includes numerous architectural and developer experience changes and improvements over YOLOv5. YOLOv8 comes with a lot of developer-convenience features, from an easy-to-use CLI to a well-structured Python package. YOLOv8 is an anchor-free model. This means it predicts directly the center of an object instead of the offset from a known anchor box.',\n",
       "  'score': 0.7606688},\n",
       " {'title': 'Ultralytics YOLO11',\n",
       "  'url': 'https://docs.ultralytics.com/models/yolo11/',\n",
       "  'content': \"Register now for\\n\\nUltralytics YOLO Vision\\nlogo\\nlogo\\n\\n# Ultralytics YOLO11\\n\\n## Overview\\n\\nYOLO11 is the latest iteration in the Ultralytics YOLO series of real-time object detectors, redefining what's possible with cutting-edge accuracy, speed, and efficiency. Building upon the impressive advancements of previous YOLO versions, YOLO11 introduces significant improvements in architecture and training methods, making it a versatile choice for a wide range of computer vision tasks. [...] YOLO11 achieves greater accuracy with fewer parameters through advancements in model design and optimization techniques. The improved architecture allows for efficient feature extraction and processing, resulting in higher mean Average Precision (mAP) on datasets like COCO while using 22% fewer parameters than YOLOv8m. This makes YOLO11 computationally efficient without compromising on accuracy, making it suitable for deployment on resource-constrained devices. [...] `@software{yolo11_ultralytics,\\n author = {Glenn Jocher and Jing Qiu},\\n title = {Ultralytics YOLO11},\\n version = {11.0.0},\\n year = {2024},\\n url = {\\n orcid = {0000-0001-5950-6979, 0000-0003-3783-7069},\\n license = {AGPL-3.0}\\n}`\\n\\nPlease note that the DOI is pending and will be added to the citation once it is available. YOLO11 models are provided under AGPL-3.0 and Enterprise licenses.\\n\\n## FAQ\\n\\n### What are the key improvements in Ultralytics YOLO11 compared to previous versions?\",\n",
       "  'score': 0.6783488},\n",
       " {'title': 'Models Supported by Ultralytics',\n",
       "  'url': 'https://docs.ultralytics.com/models/',\n",
       "  'content': 'Ultralytics YOLO11 offers enhanced capabilities such as real-time object detection, instance segmentation, pose estimation, and classification. Its optimized architecture ensures high-speed performance without sacrificing accuracy, making it ideal for a variety of applications across diverse AI domains. YOLO11 builds on previous versions with improved performance and additional features, as detailed on the YOLO11 documentation page.\\n\\n### How can I train a YOLO model on custom data?',\n",
       "  'score': 0.6219319}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Provide me the latest YOLO model version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040791cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all these tools in the list\n",
    "tools=[arxiv,wiki,tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc3a333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##initialize the LLM model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c86bf610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to figure out what Agentic AI is. Let me start by breaking down the term. \"Agentic\" might be related to \"agent,\" and \"AI\" is artificial intelligence. So maybe Agentic AI is about AI that acts as an agent? But I\\'m not sure. Let me think.\\n\\nFirst, I recall that in computer science, an agent is something that can act autonomously, make decisions, and interact with its environment. So an AI agent would be a program that can perform tasks on its own. But what makes Agentic AI special? Maybe it\\'s more advanced than regular AI agents?\\n\\nI remember reading about AI agents in the context of chatbots or virtual assistants like Siri or Alexa. They can respond to queries, perform tasks, etc. But Agentic AI might be taking that a step further. Perhaps it\\'s about AI that can handle more complex tasks, like planning, learning, adapting, and making decisions without constant human input.\\n\\nWait, I think there\\'s a specific framework or concept called Agentic AI. Maybe it\\'s part of a research paper or a specific company\\'s technology. Let me check if there are any key points associated with Agentic AI. Some sources mention that Agentic AI systems can initiate actions, have goals, and learn from experiences. They might use techniques like reinforcement learning or other machine learning methods to improve over time.\\n\\nAlso, Agentic AI might involve the ability to reason, plan, and collaborate with other agents or humans. Maybe it\\'s about creating AI that can work in dynamic environments, handle uncertainty, and have a sense of autonomy. I\\'m trying to recall if there\\'s a specific architecture or model that defines Agentic AI. Perhaps it\\'s related to large language models (LLMs) like GPT but with additional capabilities for autonomous action.\\n\\nAnother angle: in some contexts, \"agentic\" refers to the ability to take initiative. So Agentic AI would be AI that can take initiative in problem-solving, not just react to inputs. This could involve setting sub-goals, breaking down complex tasks, and executing them step by step. For example, an Agentic AI might be tasked with organizing an event, and it would autonomously book venues, send invitations, manage schedules, etc.\\n\\nBut how is this different from traditional AI? Traditional AI might be programmed to follow specific rules or respond to queries, while Agentic AI has more autonomy and adaptability. It might use a combination of different AI techniques, such as natural language processing, computer vision, robotics, and machine learning to perform a wide range of tasks.\\n\\nI should also consider if there are any notable examples or applications of Agentic AI. Companies like Google, OpenAI, or others might have developed systems under this concept. For instance, projects involving autonomous vehicles or personal AI assistants that can manage tasks on behalf of users. Maybe in business, Agentic AI is used for customer service automation, where the AI can handle customer interactions more proactively.\\n\\nThere\\'s also the aspect of safety and control. If an AI is acting autonomously, there needs to be mechanisms to ensure it behaves ethically and stays within predefined boundaries. This might involve constraints, oversight systems, or alignment with human values. So Agentic AI might also focus on these ethical considerations.\\n\\nI\\'m a bit confused about the terminology. Are there other terms similar to Agentic AI? Maybe \"autonomous AI,\" \"intelligent agent,\" or \"AI agent.\" Could Agentic AI be a marketing term used to describe more advanced AI systems? Or is it a distinct concept with specific technical requirements?\\n\\nTo summarize, Agentic AI is likely a type of AI that combines autonomous decision-making, goal-oriented behavior, adaptability, and the ability to learn and improve. It\\'s not just reactive but proactive in achieving objectives. It might involve advanced machine learning models and integration with various AI techniques to operate in complex environments. Examples could include AI systems that manage business processes, assist in research, or provide personalized services to users by taking initiative and making decisions beyond simple task execution.\\n\\nI need to verify if there are any specific technical components or frameworks associated with Agentic AI. Maybe it\\'s built on top of large language models with additional capabilities for planning and execution. For instance, using a language model to generate plans, then executing them through APIs or other systems. Some researchers might refer to this as an AI agent system, where the AI can use tools, access information, and perform actions in the real world.\\n\\nIn conclusion, Agentic AI refers to AI systems that exhibit agency by autonomously taking actions to achieve goals, adapting to new situations, learning from experiences, and interacting with their environment proactively. It\\'s a step beyond traditional AI systems that are more rule-based or reactive, emphasizing initiative, adaptability, and complex problem-solving.\\n</think>\\n\\nAgentic AI refers to a type of artificial intelligence that operates as an autonomous agent, capable of initiating, planning, and executing actions to achieve specific goals with minimal human intervention. Unlike traditional AI systems that are often reactive or rule-based, Agentic AI emphasizes **autonomy**, **proactivity**, **adaptability**, and **goal-oriented behavior**. Here\\'s a structured breakdown of its key aspects:\\n\\n---\\n\\n### **Core Characteristics of Agentic AI**\\n1. **Autonomy and Proactivity**:\\n   - **Autonomous Decision-Making**: Agentic AI can make decisions independently, often using advanced machine learning models (e.g., large language models like GPT) to analyze data and determine the best course of action.\\n   - **Proactive Behavior**: Instead of waiting for user input, it can initiate actions, such as setting reminders, solving problems preemptively, or exploring new strategies.\\n\\n2. **Goal-Oriented Planning**:\\n   - **Sub-Goal Decomposition**: Breaks down complex tasks into smaller, manageable steps. For example, organizing a project might involve creating timelines, assigning tasks, and monitoring progress.\\n   - **Dynamic Adaptation**: Adjusts plans in response to changing environments or unexpected challenges using techniques like reinforcement learning.\\n\\n3. **Learning and Improvement**:\\n   - **Continuous Learning**: Learns from past experiences to refine strategies. This could involve feedback loops where the AI evaluates its performance and iterates.\\n   - **Generalization**: Applies knowledge across different domains, such as using data from customer service interactions to improve healthcare recommendations.\\n\\n4. **Integration with Tools and Systems**:\\n   - **Tool Use**: Agentic AI can interact with external tools (e.g., APIs, databases, software) to perform real-world tasks, like booking flights or generating reports.\\n   - **Multi-Agent Collaboration**: Works with other AI agents or humans, coordinating efforts in environments like logistics or research.\\n\\n5. **Ethical and Safe Operation**:\\n   - **Constraints and Safeguards**: Designed with ethical guidelines and oversight to prevent harmful actions. This includes alignment with human values and transparency in decision-making.\\n   - **Explainability**: Provides clear reasoning for actions to ensure trust and accountability.\\n\\n---\\n\\n### **Technical Foundations**\\n- **Advanced Models**: Often built on large language models (LLMs) or multimodal systems with enhanced reasoning capabilities.\\n- **Reinforcement Learning**: Used for training in dynamic environments where trial and error are necessary.\\n- **Planning Algorithms**: Techniques like Monte Carlo Tree Search (MCTS) or hierarchical task networks help in strategic decision-making.\\n\\n---\\n\\n### **Applications of Agentic AI**\\n1. **Business Automation**:\\n   - Managing workflows, optimizing supply chains, or handling customer service through autonomous agents.\\n2. **Personal Assistance**:\\n   - AI assistants that proactively organize schedules, manage finances, or provide personalized recommendations.\\n3. **Healthcare**:\\n   - Supporting diagnostics, treatment planning, or patient monitoring by integrating data from multiple sources.\\n4. **Research and Development**:\\n   - Accelerating scientific discovery by automating experiments, analyzing data, and generating hypotheses.\\n5. **Creative Industries**:\\n   - Assisting in content creation (e.g., writing, design) by understanding user preferences and iterating on ideas.\\n\\n---\\n\\n### **Examples and Use Cases**\\n- **Autonomous Vehicles**: Navigating complex environments while adhering to safety rules and adapting to traffic.\\n- **AI-Driven Customer Service Bots**: Proactively resolving issues before users report them.\\n- **AI Researchers**: Systems like AutoML or automated code generators that design and test machine learning models independently.\\n- **Personalized Learning Tutors**: Adapting educational content to individual student needs in real time.\\n\\n---\\n\\n### **Challenges and Considerations**\\n- **Ethical Risks**: Ensuring alignment with human values and avoiding biases in decision-making.\\n- **Security**: Protecting against malicious use or unintended consequences from autonomous actions.\\n- **Transparency**: Making AI decisions interpretable to users and stakeholders.\\n- **Scalability**: Handling the complexity of real-world environments without overfitting to specific scenarios.\\n\\n---\\n\\n### **Conclusion**\\nAgentic AI represents a shift from passive to active, goal-driven systems, blending cutting-edge AI techniques with autonomous execution. While it holds transformative potential across industries, its development requires careful attention to ethics, safety, and technical robustness. As research progresses, Agentic AI is expected to become integral to next-generation applications, enabling more intelligent, adaptive, and collaborative AI systems.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1892, 'prompt_tokens': 13, 'total_tokens': 1905, 'completion_time': 9.601415358, 'prompt_time': 0.008707069, 'queue_time': 0.048376598, 'total_time': 9.610122427}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6c21d275-60e4-4389-9d80-9ced8a61c8e8-0', usage_metadata={'input_tokens': 13, 'output_tokens': 1892, 'total_tokens': 1905})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is Agentic AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c20e7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a76deda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the latest YOLO version. Let me think about how to approach this.\\n\\nFirst, YOLO, or You Only Look Once, is a popular object detection model. The versions have evolved over time, with contributions from different researchers and teams. The original YOLO was created by Joseph Redmon, and later versions like YOLOv2, YOLOv3, and YOLOv4 were developed. More recently, the BoT-SAM team has been involved in YOLO development, leading to YOLOv5 and YOLOv8. \\n\\nI remember that YOLOv8 is the latest version as of late 2023. But wait, I should verify this. The user might be looking for the most up-to-date information, so relying on my existing knowledge might not be sufficient. There could be a newer version released recently that I\\'m not aware of. \\n\\nTo ensure accuracy, I should use the Tavily search engine to check the latest developments. The Tavily search function can provide current information about the latest YOLO version. I\\'ll use the search query \"latest YOLO version 2023\" to find the most recent updates. \\n\\nBy performing this search, I can confirm whether YOLOv8 is indeed the latest or if there\\'s a newer version. This step is crucial because the field of machine learning is rapidly evolving, and new versions can be released frequently. \\n\\nAdditionally, I should consider that the user might need details on where to find the latest YOLO version, such as GitHub repositories or official websites. The search results might include links to these resources, which would be helpful for the user. \\n\\nIn summary, using Tavily to search for the latest YOLO version ensures that the information provided is current and accurate, addressing the user\\'s query effectively.\\n', 'tool_calls': [{'id': 'hnt1qcgm9', 'function': {'arguments': '{\"query\":\"latest YOLO version 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 427, 'prompt_tokens': 323, 'total_tokens': 750, 'completion_time': 2.03856478, 'prompt_time': 0.024607833, 'queue_time': 0.052226454, 'total_time': 2.063172613}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8b27c2aa-d72d-4610-9ba6-0b4195a82363-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'latest YOLO version 2023'}, 'id': 'hnt1qcgm9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 323, 'output_tokens': 427, 'total_tokens': 750})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"What is the latest yolo version? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd226ea",
   "metadata": {},
   "source": [
    "Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e12fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##state Schema\n",
    "from typing_extensions import TypedDict, List\n",
    "from langchain_core.messages import AnyMessage # Human Message or AI message\n",
    "from typing import Annotated #labelling\n",
    "from langgraph.graph.message import add_messages #reducer in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10f345f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb0bcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entire Chatbot With LangGraph\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c0fb73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "#Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "##Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # if the latest message (result) from the assistant is a tool call - tools_condition routes to tools\n",
    "    # if the latest message (result) from the assistant is not a tool call - tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "#View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "10.7759/cureus.76320\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (n3v47hyr7)\n",
      " Call ID: n3v47hyr7\n",
      "  Args:\n",
      "    query: 10.7759/cureus.76320\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"People's Attitude and Perception of the Pandemic on Twitter\", \"url\": \"https://www.cureus.com/articles/289414-peoples-attitude-and-perception-of-the-pandemic-on-twitter-a-case-study-of-covid-19-in-india\", \"content\": \"This study aims to identify and examine the emotions expressed and topics of discussion among Indian citizens related to COVID-19 third wave.\", \"score\": 0.98554}, {\"title\": \"People's Attitude and Perception of the Pandemic on Twitter - PubMed\", \"url\": \"https://pubmed.ncbi.nlm.nih.gov/39850180/\", \"content\": \"People's Attitude and Perception of the Pandemic on Twitter: A Case Study of COVID-19 in India. Cureus. 2024 Dec 24;16(12):e76320. doi: 10.7759/\", \"score\": 0.98532}, {\"title\": \"[PDF] A Case Study of COVID-19 in India\", \"url\": \"https://www.cureus.com/articles/289414-peoples-attitude-and-perception-of-the-pandemic-on-twitter-a-case-study-of-covid-19-in-india.pdf\", \"content\": \"Figure 1 depicts the methodological framework. Published via MHS-SRMIST. 2024 PV et al. Cureus 16(12): e76320. DOI 10.7759/cureus.76320.\", \"score\": 0.98467}, {\"title\": \"Suspension Trauma: A Clinical Review - PubMed\", \"url\": \"https://pubmed.ncbi.nlm.nih.gov/32656030/\", \"content\": \"Suspension trauma is a potentially dangerous outcome of the body's normal physiological response to motionless vertical suspension from a rope.\", \"score\": 0.97828}, {\"title\": \"The Cureus Journal of Medical Science: Peer-Reviewed, Open Access\", \"url\": \"https://www.cureus.com/\", \"content\": \"Image 3Specialties  *   Image 4Articles *   Image 82About Collections *   Image 84Cureus Honors Image 90Channels   *   Image 170About Channels *   Image 172Advertise With Us Image 190About Us   *   Image 195Authors *   Image 196Reviewers Image 205 Image 206 Image 400 Image 401 Image 402 Image 403 Image 404 Image 405 Image 406 Image 418 Image 419 Image 420 Image 421 Image 422 Image 423 Image 4242 Image 42592 Image 4271 Image 428221 Image 4304 Image 43179 Image 4331 Image 434143 Image 436 Image 437 Image 438 Image 439 Image 440 Image 441 Image 442 Image 443 Image 444 Image 450 ###### Cureus authors summarize their articles Image 454\", \"score\": 0.97567}]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "messages=graph.invoke({\"messages\":\"10.7759/cureus.76320\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9de3cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, My name is Meera\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Meera! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "messages=graph.invoke({\"messages\":\"Hi, My name is Meera\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
